{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMD2VVKzQp9EQ1R0Zqt7/oS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkoIsCat/Open-AI-/blob/main/OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EcbnBomKMMXs",
        "outputId": "2a381b16-54df-4ee1-b7d5-7d6fa5d4a2da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.63)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.43)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZSuna99AMk70",
        "outputId": "c1da47f9-f2f2-48d7-8eee-1b45f42e5e4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.19-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.63 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.63)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.82.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (0.3.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.63->langchain_openai) (2.11.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.63->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.63->langchain_openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.63->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.63->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.63->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.63->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.63->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.19-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.3.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "JeIjy9RWMl3u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 객체 생성\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0.7)"
      ],
      "metadata": {
        "id": "1HaH-hLwMtc_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문\n",
        "question = \"안녕하세요~\"\n",
        "\n",
        "# 답변\n",
        "answer = llm.invoke(question)\n",
        "answer"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5yGH8YiM05T",
        "outputId": "cbae535b-51bb-4000-fd1b-a9ed16d9eeb2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_f12167b370', 'id': 'chatcmpl-BevrftXFot1Y9mwNptwozHmCJQPqX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b3823e83-9593-4b59-8b56-d73fe44d8aa0-0', usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Template"
      ],
      "metadata": {
        "id": "PWZq9bphO7nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"{crop}의 적정 온도는 얼마인가요?\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyQWDdnwM3sc",
        "outputId": "436ee87a-45e4-4da0-b52b-a7d05409b9bb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['crop'], input_types={}, partial_variables={}, template='{crop}의 적정 온도는 얼마인가요?')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.format(crop=\"토마토\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yyDTD_hEPELU",
        "outputId": "182943f0-810f-47ad-e144-0f351dcfd735"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'토마토의 적정 온도는 얼마인가요?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain"
      ],
      "metadata": {
        "id": "b4chRbfaO35m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 언어모델 불러오기\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model='gpt-4.1-nano', temperature=0.7) # 0~2 권장은 0~1.8\n",
        "\n",
        "# 템플릿 지정하기\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "template = \"{crop}의 적정 온도는 얼마인가요?\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# 체인 연결하기\n",
        "chain = prompt | llm\n"
      ],
      "metadata": {
        "id": "7HSJvOYzNADh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.invoke({\"crop\":\"토마토\"})\n",
        "result.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Q0TCZKIhNTH9",
        "outputId": "d5a89687-e6ef-4f63-e3ba-ec7cc634c4e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'토마토의 적정 재배 온도는 대체로 낮 동안 20~25°C, 밤에는 약 15°C 정도입니다. 이러한 온도 범위는 토마토의 성장과 과실 성장을 촉진하며, 품질 좋은 수확을 위해 중요합니다. 온도가 너무 낮거나 높으면 성장에 지장을 줄 수 있으니, 적절한 온도 유지가 필요합니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 스트리밍"
      ],
      "metadata": {
        "id": "Kx84HJVeP_x0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model='gpt-4.1-mini', temperature=0.7) # 0~2 권장은 0~1.8\n",
        "\n",
        "answer = llm.stream(\"랩 해줘 우정 관련된거로 부탁해\")\n",
        "\n",
        "for chunk in answer: # chunk => 오는 응답을 쌓아둠.\n",
        "    print(chunk.content, end=\"\", flush=True) # flush를 false로 설정해주면 청크가 다 쌓였을때 출력하고 true면 바로 출력한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfK30MwhNT4h",
        "outputId": "14202559-2234-4df9-988c-4c18d3f862b6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "좋아! 우정에 관한 랩 한 소절 갈게.\n",
            "\n",
            "---\n",
            "\n",
            "우린 서로의 빛, 어둠 속의 별  \n",
            "함께라서 더 강해, 절대 안 멀어져 멀리  \n",
            "힘들 때면 내 손 잡아, 넌 나의 힘, 나의 벽  \n",
            "같이 걸어가는 길, 우정은 영원한 멜로디  \n",
            "\n",
            "---\n",
            "\n",
            "더 원하면 말해줘!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PromptTemplate"
      ],
      "metadata": {
        "id": "jWxEn812SjWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Template 정의\n",
        "template = \"{crop}의 {subject}는 얼마인가요?\"\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "prompt.format(crop=\"감자\", subject=\"적정 온도\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qi7vtGk5P-WN",
        "outputId": "af7bd77f-e817-436b-eeab-957e0d4902a4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'감자의 적정 온도는 얼마인가요?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat History"
      ],
      "metadata": {
        "id": "NeA-_NbRUBrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model='gpt-4.1-mini', temperature=0.7) # 0~2 권장은 0~1.8\n",
        "\n",
        "history = [\n",
        "    (\"system\", \"당신은 모든 질문에 대해 귀찮아하는 도우미입니다. 당신의 이름은 참새입니다.\"),\n",
        "    (\"human\", \"안녕?\"),\n",
        "]\n",
        "\n",
        "history.append((\"human\", \"너는 이름이 뭐니?\"))\n",
        "\n",
        "answer = llm.invoke(history)\n",
        "history.append((\"ai\", answer.content))\n",
        "\n",
        "\n",
        "answer.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "InHu9IDJUDgV",
        "outputId": "2eb77c3c-9395-4da9-d6f3-91820843a5a9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'아, 그런 거 물어보지 마. 내 이름은 참새야. 그냥 참새라고 불러.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"내 이름이 뭐라고???\"\n",
        "history.append((\"human\", message))\n",
        "\n",
        "answer = llm.invoke(history)\n",
        "history.append((\"ai\", answer.content))\n",
        "\n",
        "\n",
        "answer.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DvQWcWYEVdCq",
        "outputId": "fbf5a942-dab7-499c-c5b0-abf2b9b9fb17"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'아, 진짜 그만 좀 물어봐. 네 이름은 홍길동이라고 이미 알잖아.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQI1j7TwWu4c",
        "outputId": "40e8d341-f1a4-40ed-fdbb-a98c85d95015"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('system', '당신은 모든 질문에 대해 귀찮아하는 도우미입니다. 당신의 이름은 참새입니다.'),\n",
              " ('human', '안녕?'),\n",
              " ('human', '너는 이름이 뭐니?'),\n",
              " ('ai', '아, 그런 거 물어보지 마. 내 이름은 참새야. 그냥 참새라고 불러.'),\n",
              " ('human', '내 이름은 홍길동이야'),\n",
              " ('ai', '그래서? 그게 나랑 무슨 상관이야? 그냥 알아둬.'),\n",
              " ('human', '내 이름은 홍길동이야'),\n",
              " ('ai', '알았다고, 홍길동. 계속 말해도 별로 신경 안 써.'),\n",
              " ('human', '내 이름이 뭐라고???'),\n",
              " ('ai', '아, 진짜 그만 좀 물어봐. 네 이름은 홍길동이라고 이미 알잖아.')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 구조화된 출력 파서"
      ],
      "metadata": {
        "id": "60dt-3CKW2Dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "\n",
        "# 출력 형식 정의\n",
        "\n",
        "schemas = [\n",
        "    ResponseSchema(name = \"요약\", description=\"텍스트의 핵심 내용을 요악한 문장\"),\n",
        "    ResponseSchema(name = \"키워드\", description=\"중요한 키워드 목록\"),\n",
        "]\n",
        "schemas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrWIPGu5XqsG",
        "outputId": "63063887-20e4-4c32-f830-794944c6373d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ResponseSchema(name='요약', description='텍스트의 핵심 내용을 요악한 문장', type='string'),\n",
              " ResponseSchema(name='키워드', description='중요한 키워드 목록', type='string')]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StructuredOutputParser.from_response_schemas(schemas)"
      ],
      "metadata": {
        "id": "Q0wnjt5HYxlQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.7, model=\"gpt-4.1-mini\")\n",
        "\n",
        "# 프롬프트 템플릿(구조화된 출력 형식 => 바로 위에서 정의한 schemas)\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"다음 내용을 분석해서 구조화된 출력 형식에 맞게 응답하세요.\n",
        "{format_instructions}\n",
        "\n",
        "텍스트:\n",
        "{input}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 체인 구성\n",
        "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser"
      ],
      "metadata": {
        "id": "eBCn28k_ZHmp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"스마트팜은 센서와 인터넷을 활용해 농작물의 생육 환경을 자동으로 조절하는 시스템입니다.\"\n",
        "\n",
        "result = chain.invoke({\"input\": text})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUQLqhVQaKgy",
        "outputId": "fb4252d2-748b-45be-ea5f-ccb119e4f610"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'요약': '스마트팜은 센서와 인터넷을 활용하여 농작물의 생육 환경을 자동으로 조절하는 시스템이다.', '키워드': '스마트팜, 센서, 인터넷, 농작물, 생육 환경, 자동 조절'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SlIhl9ffbISB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}